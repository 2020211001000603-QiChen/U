#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
IEMOCAP-DA æ€§èƒ½è¯Šæ–­è„šæœ¬
ç”¨äºåˆ†ææ•°æ®é›†ç‰¹å¾å’Œå¯èƒ½çš„æ€§èƒ½é—®é¢˜
"""

import os
import sys
import pandas as pd
import numpy as np
from collections import Counter
import argparse

def analyze_dataset_statistics(data_path, dataset_name):
    """åˆ†ææ•°æ®é›†ç»Ÿè®¡ç‰¹å¾"""
    
    print("=" * 60)
    print(f"{dataset_name} æ•°æ®é›†ç»Ÿè®¡åˆ†æ")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶
    train_file = os.path.join(data_path, dataset_name, 'train.tsv')
    dev_file = os.path.join(data_path, dataset_name, 'dev.tsv')
    test_file = os.path.join(data_path, dataset_name, 'test.tsv')
    
    if not os.path.exists(train_file):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {train_file}")
        return None
    
    # è¯»å–æ•°æ®
    train_df = pd.read_csv(train_file, sep='\t', header=None)
    dev_df = pd.read_csv(dev_file, sep='\t', header=None) if os.path.exists(dev_file) else None
    test_df = pd.read_csv(test_file, sep='\t', header=None) if os.path.exists(test_file) else None
    
    # ç¡®å®šæ ‡ç­¾åˆ—ä½ç½®
    if dataset_name == 'IEMOCAP-DA':
        label_col_idx = 2
        text_col_idx = 1
    elif dataset_name == 'MELD-DA':
        label_col_idx = 3
        text_col_idx = 2
    else:
        label_col_idx = 4
        text_col_idx = 3
    
    # 1. æ•°æ®é›†å¤§å°
    print(f"\nğŸ“Š æ•°æ®é›†å¤§å°:")
    print(f"   è®­ç»ƒé›†: {len(train_df)} æ ·æœ¬")
    if dev_df is not None:
        print(f"   éªŒè¯é›†: {len(dev_df)} æ ·æœ¬")
    if test_df is not None:
        print(f"   æµ‹è¯•é›†: {len(test_df)} æ ·æœ¬")
    
    # 2. ç±»åˆ«åˆ†å¸ƒ
    print(f"\nğŸ·ï¸  ç±»åˆ«åˆ†å¸ƒ:")
    all_labels = train_df.iloc[:, label_col_idx].tolist()
    if dev_df is not None:
        all_labels.extend(dev_df.iloc[:, label_col_idx].tolist())
    
    label_counts = Counter(all_labels)
    total = len(all_labels)
    
    for label, count in sorted(label_counts.items()):
        pct = count / total * 100
        bar = 'â–ˆ' * int(pct / 2)
        print(f"   {label:10s}: {count:5d} ({pct:5.2f}%) {bar}")
    
    # 3. ç±»åˆ«ä¸å¹³è¡¡åº¦
    counts = list(label_counts.values())
    imbalance_ratio = max(counts) / min(counts) if min(counts) > 0 else float('inf')
    print(f"\n   âš–ï¸  ç±»åˆ«ä¸å¹³è¡¡åº¦: {imbalance_ratio:.2f}")
    if imbalance_ratio > 5:
        print("   âš ï¸  è­¦å‘Š: ç±»åˆ«ä¸¥é‡ä¸å¹³è¡¡ï¼Œå¯èƒ½å½±å“èšç±»æ€§èƒ½")
    elif imbalance_ratio > 3:
        print("   âš ï¸  æ³¨æ„: ç±»åˆ«å­˜åœ¨ä¸å¹³è¡¡ï¼Œå»ºè®®ä½¿ç”¨ç±»åˆ«æƒé‡")
    else:
        print("   âœ… ç±»åˆ«åˆ†å¸ƒç›¸å¯¹å¹³è¡¡")
    
    # 4. æ–‡æœ¬é•¿åº¦åˆ†æ
    print(f"\nğŸ“ æ–‡æœ¬é•¿åº¦åˆ†æ:")
    texts = train_df.iloc[:, text_col_idx].astype(str).tolist()
    if dev_df is not None:
        texts.extend(dev_df.iloc[:, text_col_idx].astype(str).tolist())
    
    lengths = [len(text.split()) for text in texts]
    lengths = [l for l in lengths if l > 0]  # è¿‡æ»¤ç©ºæ–‡æœ¬
    
    if lengths:
        print(f"   å¹³å‡é•¿åº¦: {np.mean(lengths):.2f} tokens")
        print(f"   ä¸­ä½æ•°:   {np.median(lengths):.2f} tokens")
        print(f"   æ ‡å‡†å·®:   {np.std(lengths):.2f} tokens")
        print(f"   æœ€å°å€¼:   {min(lengths)} tokens")
        print(f"   æœ€å¤§å€¼:   {max(lengths)} tokens")
        print(f"   25%åˆ†ä½:  {np.percentile(lengths, 25):.2f} tokens")
        print(f"   75%åˆ†ä½:  {np.percentile(lengths, 75):.2f} tokens")
        
        # ä¸é…ç½®çš„åºåˆ—é•¿åº¦å¯¹æ¯”
        if dataset_name == 'IEMOCAP-DA':
            config_length = 44
        elif dataset_name == 'MELD-DA':
            config_length = 70
        else:
            config_length = 30
        
        coverage = sum(1 for l in lengths if l <= config_length) / len(lengths) * 100
        print(f"\n   ğŸ“ é…ç½®åºåˆ—é•¿åº¦: {config_length}")
        print(f"   ğŸ“ˆ è¦†ç›–ç‡: {coverage:.2f}% (é•¿åº¦ <= {config_length})")
        
        if np.mean(lengths) < config_length * 0.5:
            print("   âš ï¸  è­¦å‘Š: å¹³å‡æ–‡æœ¬é•¿åº¦è¿œå°äºé…ç½®é•¿åº¦ï¼Œä¿¡æ¯å¯èƒ½ä¸è¶³")
        elif np.mean(lengths) > config_length * 0.9:
            print("   âš ï¸  æ³¨æ„: å¹³å‡æ–‡æœ¬é•¿åº¦æ¥è¿‘é…ç½®é•¿åº¦ï¼Œå¯èƒ½æœ‰æˆªæ–­")
    
    # 5. æ•°æ®è´¨é‡æ£€æŸ¥
    print(f"\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing_labels = train_df.iloc[:, label_col_idx].isna().sum()
    missing_texts = train_df.iloc[:, text_col_idx].isna().sum()
    print(f"   ç¼ºå¤±æ ‡ç­¾: {missing_labels}")
    print(f"   ç¼ºå¤±æ–‡æœ¬: {missing_texts}")
    
    # æ£€æŸ¥ç©ºæ–‡æœ¬
    empty_texts = sum(1 for t in texts if len(str(t).strip()) == 0)
    print(f"   ç©ºæ–‡æœ¬æ•°: {empty_texts}")
    
    if empty_texts > 0:
        print("   âš ï¸  è­¦å‘Š: å­˜åœ¨ç©ºæ–‡æœ¬ï¼Œå¯èƒ½å½±å“è®­ç»ƒ")
    
    # 6. ä¸MELD-DAå¯¹æ¯”ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if dataset_name == 'IEMOCAP-DA':
        meld_path = os.path.join(data_path, 'MELD-DA', 'train.tsv')
        if os.path.exists(meld_path):
            print(f"\nğŸ”„ ä¸ MELD-DA å¯¹æ¯”:")
            meld_df = pd.read_csv(meld_path, sep='\t', header=None)
            meld_texts = meld_df.iloc[:, 2].astype(str).tolist()
            meld_lengths = [len(t.split()) for t in meld_texts if len(t.split()) > 0]
            
            if meld_lengths and lengths:
                print(f"   æ–‡æœ¬é•¿åº¦å¯¹æ¯”:")
                print(f"     IEMOCAP-DA: {np.mean(lengths):.2f} Â± {np.std(lengths):.2f}")
                print(f"     MELD-DA:     {np.mean(meld_lengths):.2f} Â± {np.std(meld_lengths):.2f}")
                ratio = np.mean(lengths) / np.mean(meld_lengths)
                print(f"     æ¯”ä¾‹: {ratio:.2f} (IEMOCAP-DA / MELD-DA)")
                
                if ratio < 0.7:
                    print("     âš ï¸  IEMOCAP-DAæ–‡æœ¬æ˜æ˜¾æ›´çŸ­ï¼Œä¿¡æ¯é‡å¯èƒ½ä¸è¶³")
    
    # 7. æ€§èƒ½é—®é¢˜è¯Šæ–­
    print(f"\nğŸ’¡ æ€§èƒ½é—®é¢˜è¯Šæ–­:")
    issues = []
    suggestions = []
    
    if imbalance_ratio > 3:
        issues.append("ç±»åˆ«ä¸å¹³è¡¡")
        suggestions.append("- è€ƒè™‘ä½¿ç”¨ç±»åˆ«æƒé‡æˆ–é‡é‡‡æ ·")
    
    if lengths and np.mean(lengths) < 15:
        issues.append("æ–‡æœ¬ä¿¡æ¯é‡ä¸è¶³")
        suggestions.append("- è€ƒè™‘å¢åŠ base_dimæˆ–ä½¿ç”¨æ›´é•¿çš„ä¸Šä¸‹æ–‡")
        suggestions.append("- æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆå¹¶ç›¸é‚»å¯¹è¯ç‰‡æ®µ")
    
    if lengths and np.std(lengths) / np.mean(lengths) > 1.0:
        issues.append("æ–‡æœ¬é•¿åº¦æ–¹å·®å¤§")
        suggestions.append("- è€ƒè™‘ä½¿ç”¨åŠ¨æ€åºåˆ—é•¿åº¦æˆ–æ›´å¥½çš„paddingç­–ç•¥")
    
    if issues:
        print("   å‘ç°çš„é—®é¢˜:")
        for issue in issues:
            print(f"     âš ï¸  {issue}")
        print("\n   æ”¹è¿›å»ºè®®:")
        for suggestion in suggestions:
            print(f"     {suggestion}")
    else:
        print("   âœ… æœªå‘ç°æ˜æ˜¾çš„æ•°æ®è´¨é‡é—®é¢˜")
    
    # 8. å‚æ•°è°ƒæ•´å»ºè®®
    print(f"\nâš™ï¸  å‚æ•°è°ƒæ•´å»ºè®®:")
    print("   - é™ä½å­¦ä¹ ç‡: lr = 2e-4 (å½“å‰: 5e-4)")
    print("   - æé«˜ç›‘ç£æ¸©åº¦: train_temperature_sup = 20 (å½“å‰: 10)")
    print("   - è€ƒè™‘å¢åŠ base_dim: base_dim = 256 (å½“å‰: 128)")
    print("   - è°ƒæ•´é˜ˆå€¼ç­–ç•¥: thres = 0.05, delta = 0.02")
    
    print("\n" + "=" * 60)
    
    return {
        'dataset_size': len(train_df),
        'num_classes': len(label_counts),
        'imbalance_ratio': imbalance_ratio,
        'avg_text_length': np.mean(lengths) if lengths else 0,
        'text_length_std': np.std(lengths) if lengths else 0,
        'label_distribution': dict(label_counts)
    }

def compare_configs():
    """å¯¹æ¯”IEMOCAP-DAå’ŒMELD-DAçš„é…ç½®å·®å¼‚"""
    
    print("\n" + "=" * 60)
    print("é…ç½®å‚æ•°å¯¹æ¯”: IEMOCAP-DA vs MELD-DA")
    print("=" * 60)
    
    comparison = {
        'å‚æ•°': ['å­¦ä¹ ç‡ (lr)', 'ç›‘ç£æ¸©åº¦ (temp_sup)', 'æ— ç›‘ç£æ¸©åº¦ (temp_unsup)', 
                 'åˆå§‹é˜ˆå€¼ (thres)', 'é˜ˆå€¼å¢é‡ (delta)', 'åŸºç¡€ç»´åº¦ (base_dim)',
                 'é¢„è®­ç»ƒ (pretrain)', 'æ‰¹æ¬¡å¤§å° (batch_size)'],
        'IEMOCAP-DA': ['5e-4', '10', '20', '0.1', '0.05', '128', 'True', '64'],
        'MELD-DA': ['2e-4', '20', '20', '0.1', '0.05', '128', 'True', '64'],
        'å·®å¼‚': ['é«˜2.5å€', 'ä½50%', 'ç›¸åŒ', 'ç›¸åŒ', 'ç›¸åŒ', 'ç›¸åŒ', 'ç›¸åŒ', 'ç›¸åŒ'],
        'å»ºè®®': ['é™ä½åˆ°2e-4', 'æé«˜åˆ°20', 'ä¿æŒ', 'ä¿æŒ', 'ä¿æŒ', 'å¯å°è¯•256', 'ä¿æŒ', 'ä¿æŒ']
    }
    
    df = pd.DataFrame(comparison)
    print("\n" + df.to_string(index=False))
    
    print("\nğŸ’¡ å…³é”®å‘ç°:")
    print("   1. âš ï¸  å­¦ä¹ ç‡å·®å¼‚æœ€å¤§: IEMOCAP-DA (5e-4) vs MELD-DA (2e-4)")
    print("      â†’ å»ºè®®: é™ä½åˆ° 2e-4ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§")
    print("   2. âš ï¸  ç›‘ç£æ¸©åº¦å·®å¼‚: IEMOCAP-DA (10) vs MELD-DA (20)")
    print("      â†’ å»ºè®®: æé«˜åˆ° 20ï¼Œå­¦ä¹ æ›´å¹³æ»‘çš„åˆ†å¸ƒ")
    print("   3. âœ… å…¶ä»–å‚æ•°ç›¸åŒï¼Œä¸»è¦å·®å¼‚åœ¨è¶…å‚æ•°è®¾ç½®")

def main():
    parser = argparse.ArgumentParser(description='IEMOCAP-DA æ€§èƒ½è¯Šæ–­å·¥å…·')
    parser.add_argument('--data_path', type=str, default='Datasets',
                       help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--dataset', type=str, default='IEMOCAP-DA',
                       choices=['IEMOCAP-DA', 'MELD-DA'],
                       help='è¦åˆ†æçš„æ•°æ®é›†')
    parser.add_argument('--compare', action='store_true',
                       help='æ˜¯å¦å¯¹æ¯”MELD-DA')
    
    args = parser.parse_args()
    
    # åˆ†æIEMOCAP-DA
    stats_iemocap = analyze_dataset_statistics(args.data_path, 'IEMOCAP-DA')
    
    # å¦‚æœè¦æ±‚å¯¹æ¯”ï¼Œåˆ†æMELD-DA
    if args.compare:
        stats_meld = analyze_dataset_statistics(args.data_path, 'MELD-DA')
        
        # å¯¹æ¯”åˆ†æ
        if stats_iemocap and stats_meld:
            print("\n" + "=" * 60)
            print("æ•°æ®é›†å¯¹æ¯”åˆ†æ")
            print("=" * 60)
            
            print(f"\nğŸ“Š æ•°æ®é›†å¤§å°:")
            print(f"   IEMOCAP-DA: {stats_iemocap['dataset_size']} æ ·æœ¬")
            print(f"   MELD-DA:     {stats_meld['dataset_size']} æ ·æœ¬")
            print(f"   æ¯”ä¾‹: {stats_iemocap['dataset_size'] / stats_meld['dataset_size']:.2f}")
            
            print(f"\nğŸ“ æ–‡æœ¬é•¿åº¦:")
            print(f"   IEMOCAP-DA: {stats_iemocap['avg_text_length']:.2f} Â± {stats_iemocap['text_length_std']:.2f}")
            print(f"   MELD-DA:     {stats_meld['avg_text_length']:.2f} Â± {stats_meld['text_length_std']:.2f}")
            if stats_iemocap['avg_text_length'] < stats_meld['avg_text_length'] * 0.7:
                print("   âš ï¸  IEMOCAP-DAæ–‡æœ¬æ˜æ˜¾æ›´çŸ­")
            
            print(f"\nâš–ï¸  ç±»åˆ«ä¸å¹³è¡¡åº¦:")
            print(f"   IEMOCAP-DA: {stats_iemocap['imbalance_ratio']:.2f}")
            print(f"   MELD-DA:     {stats_meld['imbalance_ratio']:.2f}")
    
    # é…ç½®å¯¹æ¯”
    compare_configs()
    
    print("\nâœ… è¯Šæ–­å®Œæˆï¼")
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("   1. æ ¹æ®è¯Šæ–­ç»“æœè°ƒæ•´è¶…å‚æ•°")
    print("   2. è¿è¡Œå¯¹æ¯”å®éªŒéªŒè¯æ”¹è¿›æ•ˆæœ")
    print("   3. ç›‘æ§è®­ç»ƒè¿‡ç¨‹ï¼Œè§‚å¯ŸæŒ‡æ ‡å˜åŒ–")

if __name__ == '__main__':
    main()

