# UMC模型数据处理流程详解

## 完整数据流程图

```
原始输入数据
    ↓
┌─────────────────────────────────────────────────────────────┐
│                    1. 输入预处理阶段                        │
├─────────────────────────────────────────────────────────────┤
│ 文本特征: text_feats (B, L, text_dim)                      │
│    ↓ BERT编码                                                │
│    text_bert (B, L, 768)                                    │
│    ↓ 投影 + LayerNorm                                        │
│    text_feat (B, L, base_dim)                              │
│                                                             │
│ 视频特征: video_feats (B, L, video_dim)                     │
│    ↓ 投影 + LayerNorm                                        │
│    video_seq (B, L, base_dim)                              │
│                                                             │
│ 音频特征: audio_feats (B, L, audio_dim)                     │
│    ↓ 投影 + LayerNorm                                        │
│    audio_seq (B, L, base_dim)                              │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│                2. ConFEDE双投影机制 (创新点一)              │
├─────────────────────────────────────────────────────────────┤
│ 视频双投影 (可选):                                          │
│   video_seq → VideoDualProjector → enhanced_video_seq      │
│   ├─ simi_proj: 主要信息 (人物、动作、表情)                │
│   └─ dissimi_proj: 环境信息 (背景、场景、环境)             │
│                                                             │
│ 音频双投影 (可选):                                          │
│   audio_seq → AudioDualProjector → enhanced_audio_seq      │
│   ├─ simi_proj: 主要信息 (语音内容、语调、情感)            │
│   └─ dissimi_proj: 环境信息 (背景噪音、环境音、音质)       │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│                3. 维度变换和交叉注意力                      │
├─────────────────────────────────────────────────────────────┤
│ 维度变换: (B, L, base_dim) → (L, B, base_dim)              │
│                                                             │
│ 交叉注意力:                                                  │
│   text_feat_t (查询) × video_seq_t (键值) → x_video        │
│   text_feat_t (查询) × audio_seq_t (键值) → x_audio        │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│              4. 文本引导注意力 (创新点二)                    │
├─────────────────────────────────────────────────────────────┤
│ 文本引导视频注意力:                                          │
│   text_feat_t (查询) × x_video (键值) → text_guided_video  │
│                                                             │
│ 文本引导音频注意力:                                          │
│   text_feat_t (查询) × x_audio (键值) → text_guided_audio  │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│                5. 自注意力层 (创新点二)                     │
├─────────────────────────────────────────────────────────────┤
│ 特征拼接:                                                   │
│   [text_feat_t, text_guided_video, text_guided_audio]      │
│                                                             │
│ 多层自注意力:                                                │
│   combined_features → SelfAttention → attended_features    │
│   (带残差连接)                                              │
│                                                             │
│ 特征分离:                                                   │
│   enhanced_text_feat, enhanced_video_feat, enhanced_audio_feat │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│                6. 特征池化和交互                             │
├─────────────────────────────────────────────────────────────┤
│ BERT CLS特征: text_bert[:, 0] → text_bert_proj             │
│                                                             │
│ 注意力池化 (可选):                                          │
│   enhanced_video_feat + text_bert_proj → text_video_pooled  │
│   enhanced_audio_feat + text_bert_proj → text_audio_pooled  │
│                                                             │
│ 特征交互:                                                   │
│   [text_bert_proj, text_video_pooled, text_audio_pooled]   │
│   → MultiheadAttention → interacted_features                │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│                7. 门控融合机制                              │
├─────────────────────────────────────────────────────────────┤
│ 门控融合 (可选):                                            │
│   ├─ 计算权重: text_weight, video_weight, audio_weight      │
│   ├─ 权重归一化                                             │
│   └─ 加权融合: enhanced_text                                │
│                                                             │
│ 简单拼接融合 (备选):                                         │
│   concat → fusion_layer → enhanced_text                     │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│                8. 聚类优化 (创新点三)                       │
├─────────────────────────────────────────────────────────────┤
│ 聚类投影器 (可选):                                          │
│   features → ClusteringProjector → clustering_features     │
│                                                             │
│ 聚类融合器 (可选):                                          │
│   clustering_features → ClusteringFusion → fused_features  │
│                                                             │
│ 聚类损失计算:                                               │
│   ├─ 紧密度损失: 同类样本聚集                               │
│   └─ 分离度损失: 不同类样本分离                             │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│                9. 对比学习和输出                            │
├─────────────────────────────────────────────────────────────┤
│ 对比学习:                                                   │
│   features → contrastive_proj → contrastive_features       │
│   contrastive_features + labels → contrastive_loss          │
│                                                             │
│ 输出模式:                                                   │
│   ├─ 'features': 返回features                               │
│   ├─ 'contrastive': 返回features + contrastive_loss        │
│   ├─ 'train-mm': 返回features + mlp_output + losses        │
│   └─ 'pretrain-mm': 返回mlp_output + losses                │
└─────────────────────────────────────────────────────────────┘
```

## 关键创新点总结

### 创新点一：ConFEDE双投影机制
- **视频双投影**: 分别捕获主要信息(人物、动作、表情)和环境信息(背景、场景、环境)
- **音频双投影**: 分别捕获主要信息(语音内容、语调、情感)和环境信息(背景噪音、环境音、音质)
- **残差连接**: 保持原始信息不丢失

### 创新点二：文本引导注意力和自注意力
- **文本引导注意力**: 以文本为锚点，引导视频和音频特征的注意力计算
- **多层自注意力**: 对拼接后的多模态特征进行自注意力处理
- **残差连接**: 增强特征表示能力

### 创新点三：聚类优化架构
- **聚类投影器**: 专门为聚类任务设计的特征投影
- **聚类融合器**: 聚类权重计算和特征融合
- **聚类损失**: 包含紧密度和分离度损失

## 消融实验控制

模型通过多个开关控制不同组件的启用/禁用：
- `enable_video_dual`: 控制视频双投影
- `enable_audio_dual`: 控制音频双投影  
- `enable_text_guided_attention`: 控制文本引导注意力
- `enable_self_attention`: 控制自注意力层
- `enable_gated_fusion`: 控制门控融合
- `use_clustering_projector`: 控制聚类投影器
- `use_clustering_fusion`: 控制聚类融合器
- `use_attention_pooling`: 控制注意力池化
- `use_layer_norm`: 控制LayerNorm

这种设计使得模型可以进行全面的消融实验，验证每个组件的有效性。
