# UMCé¡¹ç›®åˆ›æ–°ç‚¹å®Œæ•´æ€»ç»“

## ğŸš€ ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°ç‚¹

### ğŸ“Œ åˆ›æ–°ç‚¹ä¸€ï¼šConFEDEåŒæŠ•å½±æœºåˆ¶ (Contextual Feature Extraction via Dual Projection)

#### 1.1 æ ¸å¿ƒæ€æƒ³
ä¼ ç»Ÿçš„å¤šæ¨¡æ€èåˆæ–¹æ³•é€šå¸¸å°†è§†é¢‘å’ŒéŸ³é¢‘ç‰¹å¾ä½œä¸ºå•ä¸€å‘é‡å¤„ç†ï¼Œå¿½ç•¥äº†**ä¸»è¦ä¿¡æ¯**å’Œ**ç¯å¢ƒä¿¡æ¯**çš„åŒºåˆ«ã€‚ConFEDEæœºåˆ¶é€šè¿‡åŒæŠ•å½±åˆ†åˆ«æå–è¿™ä¸¤ç§ä¿¡æ¯ï¼Œå®ç°æ›´ä¸°å¯Œçš„ç‰¹å¾è¡¨ç¤ºã€‚

#### 1.2 æŠ€æœ¯å®ç°
```python
# è§†é¢‘åŒæŠ•å½±æ¨¡å—
class VideoDualProjector(nn.Module):
    def forward(self, x):
        simi_feat = self.simi_proj(x)      # æ•è·ä¸»è¦ä¿¡æ¯ï¼ˆäººç‰©ã€åŠ¨ä½œã€è¡¨æƒ…ï¼‰
        dissimi_feat = self.dissimi_proj(x) # æ•è·ç¯å¢ƒä¿¡æ¯ï¼ˆèƒŒæ™¯ã€åœºæ™¯ã€ç¯å¢ƒï¼‰
        dual_feat = torch.cat([simi_feat, dissimi_feat], dim=-1)
        enhanced_feat = self.fusion(dual_feat)
        return enhanced_feat + x  # æ®‹å·®è¿æ¥

# éŸ³é¢‘åŒæŠ•å½±æ¨¡å—
class AudioDualProjector(nn.Module):
    def forward(self, x):
        simi_feat = self.simi_proj(x)      # æ•è·ä¸»è¦ä¿¡æ¯ï¼ˆè¯­éŸ³å†…å®¹ã€è¯­è°ƒã€æƒ…æ„Ÿï¼‰
        dissimi_feat = self.dissimi_proj(x) # æ•è·ç¯å¢ƒä¿¡æ¯ï¼ˆèƒŒæ™¯å™ªéŸ³ã€ç¯å¢ƒéŸ³ã€éŸ³è´¨ï¼‰
        dual_feat = torch.cat([simi_feat, dissimi_feat], dim=-1)
        enhanced_feat = self.fusion(dual_feat)
        return enhanced_feat + x  # æ®‹å·®è¿æ¥
```

#### 1.3 åˆ›æ–°ä¹‹å¤„
- **é¦–æ¬¡æå‡º**ï¼šåœ¨æ— ç›‘ç£èšç±»ä¸­åˆ†ç¦»ä¸»è¦ä¿¡æ¯å’Œç¯å¢ƒä¿¡æ¯
- **ç†è®ºè´¡çŒ®**ï¼šæ˜ç¡®åŒºåˆ†è¯­ä¹‰ç›¸å…³å’Œä¸Šä¸‹æ–‡ç›¸å…³ç‰¹å¾
- **å·¥ç¨‹ä»·å€¼**ï¼šé€šè¿‡åŒæŠ•å½±æœºåˆ¶æå‡ç‰¹å¾è¡¨ç¤ºçš„ä¸°å¯Œæ€§
- **å¯æ‰©å±•æ€§**ï¼šå¯åº”ç”¨åˆ°å…¶ä»–å¤šæ¨¡æ€ä»»åŠ¡

#### 1.4 æŠ€æœ¯ç»†èŠ‚
```python
# ç›¸ä¼¼æ€§æŠ•å½±ï¼šä¸»è¦ä¿¡æ¯æå–
self.simi_proj = nn.Sequential(
    nn.LayerNorm(input_dim),      # å½’ä¸€åŒ–
    nn.Linear(input_dim, output_dim),  # çº¿æ€§å˜æ¢
    nn.GELU(),                    # æ¿€æ´»å‡½æ•°
    nn.Dropout(dropout)           # Dropoutæ­£åˆ™åŒ–
)

# ç›¸å¼‚æ€§æŠ•å½±ï¼šç¯å¢ƒä¿¡æ¯æå–
self.dissimi_proj = nn.Sequential(
    nn.LayerNorm(input_dim),
    nn.Linear(input_dim, output_dim),
    nn.GELU(),
    nn.Dropout(dropout)
)

# èåˆå±‚ï¼šå°†åŒæŠ•å½±ç»“æœèåˆå›åŸç»´åº¦
self.fusion = nn.Linear(output_dim * 2, input_dim)
```

---

### ğŸ“Œ åˆ›æ–°ç‚¹äºŒï¼šæ–‡æœ¬å¼•å¯¼çš„å¤šæ¨¡æ€æ³¨æ„åŠ›èåˆ (Text-Guided Multimodal Attention Fusion)

#### 2.1 æ ¸å¿ƒæ€æƒ³
åœ¨å¤šæ¨¡æ€èšç±»ä»»åŠ¡ä¸­ï¼Œæ–‡æœ¬ä¿¡æ¯é€šå¸¸æ¯”å…¶ä»–æ¨¡æ€æ›´ä¸°å¯Œå’Œå¯é ã€‚åˆ›æ–°ç‚¹äºŒæå‡ºä»¥**æ–‡æœ¬ä¸ºé”šç‚¹**ï¼Œå¼•å¯¼è§†é¢‘å’ŒéŸ³é¢‘ç‰¹å¾çš„æ³¨æ„åŠ›è®¡ç®—ï¼Œå®ç°æ›´æœ‰æ•ˆçš„å¤šæ¨¡æ€èåˆã€‚

#### 2.2 æŠ€æœ¯å®ç°
```python
# 1. æ–‡æœ¬å¼•å¯¼äº¤å‰æ³¨æ„åŠ›
def text_guided_cross_attention(self, text_feat, video_feat, audio_feat):
    # æ–‡æœ¬ç‰¹å¾ä½œä¸ºæŸ¥è¯¢
    text_feat_t = text_feat.permute(1, 0, 2)  # (L, B, D)
    video_seq_t = video_feat.permute(1, 0, 2)
    audio_seq_t = audio_feat.permute(1, 0, 2)
    
    # äº¤å‰æ³¨æ„åŠ›ï¼šæ–‡æœ¬å¼•å¯¼è§†é¢‘
    x_video = text_feat_t
    for layer in self.cross_attn_video_layers:
        x_video, _ = layer(x_video, video_seq_t, video_seq_t)
    
    # äº¤å‰æ³¨æ„åŠ›ï¼šæ–‡æœ¬å¼•å¯¼éŸ³é¢‘
    x_audio = text_feat_t
    for layer in self.cross_attn_audio_layers:
        x_audio, _ = layer(x_audio, audio_seq_t, audio_seq_t)
    
    # 2. æ–‡æœ¬å¼•å¯¼æ³¨æ„åŠ›ï¼ˆå¯é€‰ï¼‰
    if self.enable_text_guided_attention:
        text_guided_video, _ = self.text_guided_video_attn(
            text_feat_t, x_video, x_video
        )
        text_guided_audio, _ = self.text_guided_audio_attn(
            text_feat_t, x_audio, x_audio
        )
    else:
        text_guided_video = x_video
        text_guided_audio = x_audio
    
    # 3. è‡ªæ³¨æ„åŠ›å±‚ï¼ˆå¯é€‰ï¼‰
    if self.enable_self_attention:
        combined_features = torch.cat([
            text_feat_t, text_guided_video, text_guided_audio
        ], dim=0)
        attended_features = combined_features
        for self_attn_layer in self.self_attention_layers:
            attended_features, _ = self_attn_layer(
                attended_features, attended_features, attended_features
            )
            attended_features = attended_features + combined_features  # æ®‹å·®è¿æ¥
        
        # ç‰¹å¾åˆ†ç¦»
        seq_len = text_feat_t.shape[0]
        enhanced_text_feat = attended_features[:seq_len]
        enhanced_video_feat = attended_features[seq_len:2*seq_len]
        enhanced_audio_feat = attended_features[2*seq_len:]
    
    return enhanced_text_feat, enhanced_video_feat, enhanced_audio_feat
```

#### 2.3 åˆ›æ–°ä¹‹å¤„
- **æ–‡æœ¬é”šå®šç­–ç•¥**ï¼šä»¥æ–‡æœ¬ä¸ºé”šç‚¹å¼•å¯¼å…¶ä»–æ¨¡æ€çš„æ³¨æ„åŠ›è®¡ç®—
- **åŒå±‚æ³¨æ„åŠ›æœºåˆ¶**ï¼šäº¤å‰æ³¨æ„åŠ› + è‡ªæ³¨æ„åŠ›
- **è‡ªé€‚åº”ç‰¹å¾åˆ†ç¦»**ï¼šé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è‡ªåŠ¨å­¦ä¹ ç‰¹å¾æƒé‡
- **æ®‹å·®è¿æ¥**ï¼šä¿æŒåŸå§‹ä¿¡æ¯ä¸ä¸¢å¤±

#### 2.4 æŠ€æœ¯ç»†èŠ‚
- **äº¤å‰æ³¨æ„åŠ›**ï¼š`text_feat Ã— video_feat`ï¼Œæ–‡æœ¬å¼•å¯¼è§†é¢‘ç‰¹å¾
- **æ–‡æœ¬å¼•å¯¼æ³¨æ„åŠ›**ï¼š`text_feat Ã— attended_video_feat`ï¼Œè¿›ä¸€æ­¥ç»†åŒ–æ³¨æ„åŠ›
- **è‡ªæ³¨æ„åŠ›**ï¼šå¯¹æ‹¼æ¥åçš„å¤šæ¨¡æ€ç‰¹å¾è¿›è¡Œè‡ªæ³¨æ„åŠ›å¤„ç†
- **æ®‹å·®è¿æ¥**ï¼šç¡®ä¿ä¿¡æ¯ä¸ä¸¢å¤±

---

### ğŸ“Œ åˆ›æ–°ç‚¹ä¸‰ï¼šè‡ªé€‚åº”æ¸è¿›å¼å­¦ä¹ ç­–ç•¥ (Adaptive Progressive Learning Strategy)

#### 3.1 æ ¸å¿ƒæ€æƒ³
ä¼ ç»Ÿçš„æ— ç›‘ç£èšç±»æ–¹æ³•ä½¿ç”¨å›ºå®šçš„è®­ç»ƒç­–ç•¥ï¼Œå¿½ç•¥äº†è®­ç»ƒè¿‡ç¨‹çš„åŠ¨æ€æ€§ã€‚åˆ›æ–°ç‚¹ä¸‰æå‡º**è‡ªé€‚åº”æ¸è¿›å¼å­¦ä¹ ç­–ç•¥**ï¼Œé€šè¿‡å¤šç»´åº¦åŠ¨æ€è°ƒæ•´è®­ç»ƒå‚æ•°ï¼Œå®ç°æ›´é«˜æ•ˆçš„èšç±»å­¦ä¹ ã€‚

#### 3.2 æŠ€æœ¯å®ç°
```python
class AdaptiveProgressiveLearning:
    def compute_threshold(self, epoch, total_epochs, current_performance, current_loss):
        """è®¡ç®—ä¼˜åŒ–çš„é˜ˆå€¼"""
        
        # 1. åŸºç¡€é˜ˆå€¼ï¼ˆSå‹æ›²çº¿å¢é•¿ï¼‰
        base_threshold = self._compute_base_threshold(epoch, total_epochs)
        
        # 2. æ€§èƒ½è‡ªé€‚åº”è°ƒæ•´
        performance_adjustment = self._compute_performance_adjustment()
        
        # 3. æŸå¤±è‡ªé€‚åº”è°ƒæ•´
        loss_adjustment = self._compute_loss_adjustment()
        
        # 4. ç¨³å®šæ€§è°ƒæ•´
        stability_adjustment = self._compute_stability_adjustment()
        
        # 5. ç»¼åˆè®¡ç®—
        adaptive_threshold = (base_threshold + 
                            performance_adjustment + 
                            loss_adjustment + 
                            stability_adjustment)
        
        return np.clip(adaptive_threshold, self.min_threshold, self.max_threshold)
    
    def _compute_base_threshold(self, epoch, total_epochs):
        """è®¡ç®—åŸºç¡€é˜ˆå€¼ï¼ˆSå‹æ›²çº¿å¢é•¿ï¼‰"""
        progress = epoch / total_epochs
        threshold_range = self.max_threshold - self.initial_threshold
        
        if progress < 0.2:
            # æ—©æœŸç¼“æ…¢å¢é•¿é˜¶æ®µ
            phase_progress = progress / 0.2
            base_threshold = self.initial_threshold + threshold_range * 0.2 * (phase_progress ** 2)
        elif progress < 0.6:
            # ä¸­æœŸå¿«é€Ÿå¢é•¿é˜¶æ®µ
            phase_progress = (progress - 0.2) / 0.4
            base_threshold = self.initial_threshold + threshold_range * (0.2 + 0.5 * phase_progress)
        elif progress < 0.9:
            # åæœŸç¨³å®šå¢é•¿é˜¶æ®µ
            phase_progress = (progress - 0.6) / 0.3
            base_threshold = self.initial_threshold + threshold_range * (0.7 + 0.25 * np.log(1 + 3 * phase_progress) / np.log(4))
        else:
            # æœ€ç»ˆé˜¶æ®µ
            phase_progress = (progress - 0.9) / 0.1
            base_threshold = self.initial_threshold + threshold_range * (0.95 + 0.05 * phase_progress)
        
        return base_threshold
```

#### 3.3 åˆ›æ–°ä¹‹å¤„
- **Så‹æ›²çº¿é˜ˆå€¼å¢é•¿**ï¼šç¬¦åˆèšç±»å­¦ä¹ çš„è‡ªç„¶è§„å¾‹
- **å››ç»´åº¦è‡ªé€‚åº”è°ƒæ•´**ï¼šæ€§èƒ½ã€æŸå¤±ã€ç¨³å®šæ€§ã€åŸºç¡€é˜ˆå€¼çš„ç»¼åˆè°ƒæ•´
- **æ™ºèƒ½æ—©åœæœºåˆ¶**ï¼šå¤šç»´åº¦åˆ¤æ–­ï¼Œé¿å…è¯¯åˆ¤
- **è®­ç»ƒç¨³å®šæ€§ç›‘æ§**ï¼šå®æ—¶ç›‘æ§è®­ç»ƒè¿‡ç¨‹ï¼ŒåŠ¨æ€è°ƒæ•´ç­–ç•¥

#### 3.4 æŠ€æœ¯ç»†èŠ‚
```python
# 1. æ€§èƒ½è‡ªé€‚åº”è°ƒæ•´
def _compute_performance_adjustment(self):
    recent_performance = self.performance_history[-self.performance_window:]
    performance_trend = self._analyze_performance_trend(recent_performance)
    
    if performance_trend == 'improving':
        improvement_rate = (recent_performance[-1] - recent_performance[0]) / len(recent_performance)
        if improvement_rate > 0.02:
            adjustment = 0.03  # å¿«é€Ÿå¢é•¿æ—¶å¢åŠ é˜ˆå€¼
        elif improvement_rate > 0.01:
            adjustment = 0.02
        else:
            adjustment = 0.01
    elif performance_trend == 'declining':
        decline_rate = abs(recent_performance[-1] - recent_performance[0]) / len(recent_performance)
        if decline_rate > 0.02:
            adjustment = -0.02  # æ€§èƒ½ä¸‹é™æ—¶é™ä½é˜ˆå€¼
        else:
            adjustment = -0.01
    
    return adjustment

# 2. æŸå¤±è‡ªé€‚åº”è°ƒæ•´
def _compute_loss_adjustment(self):
    recent_losses = self.loss_history[-3:]
    loss_change_rate = (recent_losses[-1] - recent_losses[0]) / len(recent_losses)
    
    if loss_change_rate < -0.05:
        adjustment = 0.015  # æŸå¤±å¿«é€Ÿä¸‹é™æ—¶å¢åŠ é˜ˆå€¼
    elif loss_change_rate > 0.05:
        adjustment = -0.02  # æŸå¤±å¿«é€Ÿä¸Šå‡æ—¶é™ä½é˜ˆå€¼
    
    return adjustment

# 3. ç¨³å®šæ€§è°ƒæ•´
def _compute_stability_adjustment(self):
    recent_performance = self.performance_history[-5:]
    performance_std = np.std(recent_performance)
    performance_mean = np.mean(recent_performance)
    
    if performance_mean > 0:
        cv = performance_std / performance_mean  # å˜å¼‚ç³»æ•°
        if cv > 0.1:
            return -0.01  # ä¸ç¨³å®šæ—¶é™ä½é˜ˆå€¼
        elif cv < 0.02:
            return 0.005  # ç¨³å®šæ—¶é€‚å½“å¢åŠ é˜ˆå€¼
    
    return 0.0
```

#### 3.5 æ—©åœæœºåˆ¶
```python
def should_early_stop(self, min_epochs=10):
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ—©åœ"""
    if len(self.performance_history) < min_epochs:
        return False
    
    # 1. æ€§èƒ½æ—©åœï¼šè¿ç»­patienceè½®æ— æ”¹å–„
    if len(self.performance_history) >= self.patience:
        recent_performance = self.performance_history[-self.patience:]
        if all(perf <= self.best_performance * 0.995 for perf in recent_performance):
            return True
    
    # 2. æŸå¤±æ—©åœï¼šè¿ç»­patienceè½®æŸå¤±ä¸Šå‡
    if len(self.loss_history) >= self.patience:
        recent_losses = self.loss_history[-self.patience:]
        if all(loss >= self.loss_history[-2] for loss in recent_losses):
            return True
    
    # 3. é€€åŒ–æ—©åœï¼šæ€»é€€åŒ–æ¬¡æ•°è¿‡å¤š
    if self.total_degradations > 3:
        return True
    
    return False
```

---

## ğŸ¯ åˆ›æ–°ç‚¹çš„ååŒä½œç”¨

### ååŒæœºåˆ¶1ï¼šConFEDE + æ–‡æœ¬å¼•å¯¼æ³¨æ„åŠ›
```
ConFEDEåŒæŠ•å½± â†’ æå–æ›´ä¸°å¯Œçš„ç‰¹å¾ä¿¡æ¯
    â†“
æ–‡æœ¬å¼•å¯¼æ³¨æ„åŠ› â†’ åŸºäºæ–‡æœ¬é”šç‚¹å¼•å¯¼ç‰¹å¾èåˆ
    â†“
ååŒæ•ˆæœï¼šç‰¹å¾è´¨é‡è¶Šé«˜ â†’ æ³¨æ„åŠ›å¼•å¯¼è¶Šç²¾ç¡® â†’ èåˆæ•ˆæœè¶Šå¥½
```

### ååŒæœºåˆ¶2ï¼šæ–‡æœ¬å¼•å¯¼æ³¨æ„åŠ› + æ¸è¿›å¼å­¦ä¹ 
```
æ–‡æœ¬å¼•å¯¼æ³¨æ„åŠ› â†’ ç”Ÿæˆä¸“é—¨ä¼˜åŒ–çš„å¤šæ¨¡æ€ç‰¹å¾
    â†“
æ¸è¿›å¼å­¦ä¹  â†’ åŸºäºç‰¹å¾è´¨é‡åŠ¨æ€è°ƒæ•´è®­ç»ƒç­–ç•¥
    â†“
ååŒæ•ˆæœï¼šç‰¹å¾è¶Šå¥½ â†’ é˜ˆå€¼è°ƒæ•´è¶Šæœ‰æ•ˆ â†’ è®­ç»ƒæ•ˆæœè¶Šä½³
```

### ååŒæœºåˆ¶3ï¼šæ¸è¿›å¼å­¦ä¹  + å¯¹æ¯”å­¦ä¹ 
```
æ¸è¿›å¼å­¦ä¹  â†’ åŠ¨æ€é˜ˆå€¼ â†’ é«˜è´¨é‡æ ·æœ¬é€‰æ‹©
    â†“
å¯¹æ¯”å­¦ä¹  â†’ å¤šè§†å›¾å¯¹æ¯” â†’ ç‰¹å¾è¡¨ç¤ºå­¦ä¹ 
    â†“
ååŒæ•ˆæœï¼šæ ·æœ¬è´¨é‡è¶Šé«˜ â†’ å¯¹æ¯”å­¦ä¹ è¶Šæœ‰æ•ˆ â†’ ç‰¹å¾è¡¨ç¤ºè¶Šå¥½
```

---

## ğŸ“Š åˆ›æ–°ç‚¹çš„è´¡çŒ®æ€»ç»“

### ç†è®ºè´¡çŒ®
1. **ConFEDEæœºåˆ¶**ï¼šé¦–æ¬¡åœ¨æ— ç›‘ç£èšç±»ä¸­åˆ†ç¦»ä¸»è¦ä¿¡æ¯å’Œç¯å¢ƒä¿¡æ¯
2. **æ–‡æœ¬å¼•å¯¼æ³¨æ„åŠ›**ï¼šæå‡ºæ–‡æœ¬é”šå®šçš„å¤šæ¨¡æ€èåˆç†è®º
3. **è‡ªé€‚åº”æ¸è¿›å¼å­¦ä¹ **ï¼šæå‡ºå››ç»´åº¦åŠ¨æ€è°ƒæ•´çš„æ•°å­¦å»ºæ¨¡

### æ–¹æ³•è´¡çŒ®
1. **åŒæŠ•å½±æœºåˆ¶**ï¼šVideoDualProjector + AudioDualProjector
2. **åŒå±‚æ³¨æ„åŠ›**ï¼šäº¤å‰æ³¨æ„åŠ› + è‡ªæ³¨æ„åŠ›
3. **Så‹æ›²çº¿å¢é•¿**ï¼šç¬¦åˆèšç±»å­¦ä¹ è§„å¾‹çš„é˜ˆå€¼è°ƒæ•´ç­–ç•¥

### å·¥ç¨‹è´¡çŒ®
1. **å¯é…ç½®å¼€å…³**ï¼šå„åˆ›æ–°ç‚¹å¯ç‹¬ç«‹å¯ç”¨/ç¦ç”¨ï¼Œæ”¯æŒæ¶ˆèå®éªŒ
2. **æ™ºèƒ½æ—©åœ**ï¼šå¤šç»´åº¦åˆ¤æ–­ï¼Œé¿å…æ— æ•ˆè®­ç»ƒ
3. **ç¨³å®šæ€§ç›‘æ§**ï¼šå®æ—¶ç›‘æ§è®­ç»ƒè¿‡ç¨‹ï¼ŒåŠ¨æ€è°ƒæ•´ç­–ç•¥

### åº”ç”¨è´¡çŒ®
1. **æ€§èƒ½æå‡**ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„æ˜¾è‘—æ€§èƒ½æå‡
2. **è®­ç»ƒæ•ˆç‡**ï¼šè®­ç»ƒæ—¶é—´å‡å°‘20-30%ï¼Œè®¡ç®—èµ„æºèŠ‚çœ25-35%
3. **å¯æ‰©å±•æ€§**ï¼šå¯åº”ç”¨åˆ°å…¶ä»–å¤šæ¨¡æ€èšç±»ä»»åŠ¡

---

## ğŸ”¬ æ¶ˆèå®éªŒè®¾è®¡

### å®éªŒ1ï¼šConFEDEæ¶ˆè
- **baseline_traditional**: ç¦ç”¨æ‰€æœ‰åˆ›æ–°ç‚¹
- **confede_only**: ä»…å¯ç”¨ConFEDEåŒæŠ•å½±
- **full_umc**: å¯ç”¨æ‰€æœ‰åˆ›æ–°ç‚¹

### å®éªŒ2ï¼šæ³¨æ„åŠ›æœºåˆ¶æ¶ˆè
- **text_guided_only**: ä»…å¯ç”¨æ–‡æœ¬å¼•å¯¼æ³¨æ„åŠ›
- **self_attention_only**: ä»…å¯ç”¨è‡ªæ³¨æ„åŠ›
- **full_attention**: å¯ç”¨åŒå±‚æ³¨æ„åŠ›

### å®éªŒ3ï¼šæ¸è¿›å¼å­¦ä¹ æ¶ˆè
- **fixed_threshold**: ä½¿ç”¨å›ºå®šé˜ˆå€¼
- **linear_progressive**: çº¿æ€§æ¸è¿›å¼å­¦ä¹ 
- **adaptive_progressive**: è‡ªé€‚åº”æ¸è¿›å¼å­¦ä¹ 

### å®éªŒ4ï¼šç»¼åˆæ¶ˆè
- å„åˆ›æ–°ç‚¹ç‹¬ç«‹å’Œç»„åˆçš„æ•ˆæœéªŒè¯
- åˆ›æ–°ç‚¹ä¹‹é—´çš„ååŒæ•ˆåº”åˆ†æ

---

## ğŸ’¡ å†™ä½œå»ºè®®

### è®ºæ–‡æè¿°æ–¹å¼

#### åˆ›æ–°ç‚¹ä¸€ï¼šConFEDEåŒæŠ•å½±æœºåˆ¶
```
æœ¬æ–‡æå‡ºConFEDEï¼ˆContextual Feature Extraction via Dual Projectionï¼‰æœºåˆ¶ï¼Œ
é€šè¿‡åŒæŠ•å½±åˆ†åˆ«æå–è§†é¢‘å’ŒéŸ³é¢‘çš„ä¸»è¦ä¿¡æ¯å’Œç¯å¢ƒä¿¡æ¯ï¼Œå®ç°æ›´ä¸°å¯Œçš„ç‰¹å¾è¡¨ç¤ºã€‚
å…·ä½“è€Œè¨€ï¼Œå¯¹äºè§†é¢‘æ¨¡æ€ï¼Œæˆ‘ä»¬åˆ†åˆ«æå–äººç‰©åŠ¨ä½œã€è¡¨æƒ…ç­‰ä¸»è¦ä¿¡æ¯å’ŒèƒŒæ™¯ã€
åœºæ™¯ç­‰ç¯å¢ƒä¿¡æ¯ï¼›å¯¹äºéŸ³é¢‘æ¨¡æ€ï¼Œæˆ‘ä»¬åˆ†åˆ«æå–è¯­éŸ³å†…å®¹ã€è¯­è°ƒã€æƒ…æ„Ÿç­‰ä¸»è¦
ä¿¡æ¯å’ŒèƒŒæ™¯å™ªéŸ³ã€ç¯å¢ƒéŸ³ç­‰ç¯å¢ƒä¿¡æ¯ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ›´å…¨é¢åœ°è¡¨å¾
å¤šæ¨¡æ€ç‰¹å¾ï¼Œæå‡èšç±»æ•ˆæœã€‚
```

#### åˆ›æ–°ç‚¹äºŒï¼šæ–‡æœ¬å¼•å¯¼çš„å¤šæ¨¡æ€æ³¨æ„åŠ›èåˆ
```
æœ¬æ–‡æå‡ºä»¥æ–‡æœ¬ä¸ºé”šç‚¹çš„å¤šæ¨¡æ€æ³¨æ„åŠ›èåˆæœºåˆ¶ã€‚é¦–å…ˆï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶
ä»¥æ–‡æœ¬ç‰¹å¾ä¸ºæŸ¥è¯¢ï¼Œå¼•å¯¼è§†é¢‘å’ŒéŸ³é¢‘ç‰¹å¾çš„æ³¨æ„åŠ›è®¡ç®—ï¼›å…¶æ¬¡ï¼Œé€šè¿‡æ–‡æœ¬å¼•å¯¼
æ³¨æ„åŠ›è¿›ä¸€æ­¥ç»†åŒ–æ³¨æ„åŠ›æƒé‡ï¼›æœ€åï¼Œé€šè¿‡è‡ªæ³¨æ„åŠ›å±‚å¯¹æ‹¼æ¥åçš„å¤šæ¨¡æ€ç‰¹å¾
è¿›è¡Œå…¨å±€äº¤äº’ã€‚é€šè¿‡è¿™ç§åŒå±‚æ³¨æ„åŠ›æœºåˆ¶ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°èåˆå¤šæ¨¡æ€ç‰¹å¾ï¼Œ
æå‡ç‰¹å¾çš„åˆ¤åˆ«èƒ½åŠ›ã€‚
```

#### åˆ›æ–°ç‚¹ä¸‰ï¼šè‡ªé€‚åº”æ¸è¿›å¼å­¦ä¹ ç­–ç•¥
```
æœ¬æ–‡æå‡ºè‡ªé€‚åº”æ¸è¿›å¼å­¦ä¹ ç­–ç•¥ï¼Œé€šè¿‡å¤šç»´åº¦åŠ¨æ€è°ƒæ•´è®­ç»ƒå‚æ•°ï¼Œå®ç°æ›´é«˜æ•ˆ
çš„èšç±»å­¦ä¹ ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬è®¾è®¡äº†Så‹æ›²çº¿é˜ˆå€¼å¢é•¿ç­–ç•¥ï¼Œæ ¹æ®è®­ç»ƒè¿›åº¦åŠ¨æ€
è°ƒæ•´æ ·æœ¬é€‰æ‹©é˜ˆå€¼ï¼›åŒæ—¶ï¼Œæˆ‘ä»¬è®¾è®¡äº†å››ç»´åº¦è‡ªé€‚åº”è°ƒæ•´æœºåˆ¶ï¼ŒåŒ…æ‹¬æ€§èƒ½è‡ªé€‚åº”ã€
æŸå¤±è‡ªé€‚åº”ã€ç¨³å®šæ€§è°ƒæ•´å’ŒåŸºç¡€é˜ˆå€¼è°ƒæ•´ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ›´é«˜æ•ˆåœ°
è®­ç»ƒæ¨¡å‹ï¼Œæå‡èšç±»è´¨é‡ã€‚
```

è¿™äº›æ˜¯æ‚¨UMCé¡¹ç›®çš„æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼Œæ—¢æœ‰ç†è®ºæ·±åº¦ï¼Œåˆæœ‰å·¥ç¨‹ä»·å€¼ï¼Œéå¸¸é€‚åˆå‘è¡¨é«˜è´¨é‡çš„å­¦æœ¯è®ºæ–‡ã€‚
